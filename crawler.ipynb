{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f853efa",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a8f40f",
   "metadata": {},
   "source": [
    "##### (import 안될 경우) 실행에 필요한 라이브러리 설치바람"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d049d9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "#from selenium.webdriver.chrome.options import Options\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "#import html5lib\n",
    "import urllib3\n",
    "import os\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "16d18db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해쉬 생성용 라이브러리\n",
    "import hashlib as hlb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4b712ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유의사항 : 크롬 브라우저로 데이터 수집을 잘 못할 경우, 파이어폭스 브라우저 사용도 시도해 보기 바람.\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "#from selenium.webdriver.firefox.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a4843535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAY 글자 수 늘리기 : 데이터프레임 열람시 활용 가능 (40 <-> 4000)\n",
    "#pd.options.display.max_colwidth = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c3c3a4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 즉석 설치가 필요할 경우 해당 커맨드 사용 권장\n",
    "#!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a08f8b9",
   "metadata": {},
   "source": [
    "### Config (new, old)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3aceb1",
   "metadata": {},
   "source": [
    "##### 유의사항 : CSS 가 수집에 유리할지 XPATH 가 수집에 유리할지는 게시판마다 다름 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "48de4723",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONFIG 1 ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "# 데이터 수집을 시작할 페이지 번호\n",
    "start_page = 1\n",
    "# 마지막 페이지 번호\n",
    "end_page = 2073\n",
    "# 마지막 페이지 글 수\n",
    "num_a_fin = 2\n",
    "# 한 페이지에 보여지는 글 개수\n",
    "cnt_a = 10\n",
    "### CONFIG 2 ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "### 시작 url\n",
    "url_str_ = 'https://www.sejong.go.kr/bbs/R0079/list.do?pageIndex={}'\n",
    "# (게시판 글 리스트에서의) 글 제목 (XPATH OR CSS)\n",
    "# 유의사항 : 숫자가 1부터 +1씩 순차적 증가가 아닐 경우, 밑의 실행 코드 부분을 수정해야 함.\n",
    "article_attr = '//*[@id=\"txt\"]/div/div[2]/table/tbody/tr[{}]/td[2]/a'\n",
    "### CONFIG 3 ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "# 유의사항 : XPATH일 때, 그 속성값 수가 2개 초과일 경우 CSS로 바꾸는 것을 추천.\n",
    "# 글 제목 (XPATH OR CSS)\n",
    "ttl_attr1 = r'//*[@id=\"txt\"]/div/div[1]/div[1]/h2'\n",
    "#ttl_attr2 = r'//*[@id=\"txt\"]/div/div[1]/div[1]/h2'\n",
    "# 글 작성일 (XPATH OR CSS)\n",
    "dt_attr1 = r'//*[@id=\"txt\"]/div/div[1]/div[1]/span[3]'\n",
    "#dt_attr2 = r'//*[@id=\"txt\"]/div/div[1]/div[1]/span[3]'\n",
    "# 글 내용 ((태그가) 두 개인 경우 cntnt_attr2  주석 풀고 추가 입력) (XPATH OR CSS)\n",
    "cntnt_attr1 = r'//*[@id=\"txt\"]/div/div[1]/div[3]'\n",
    "#cntnt_attr2 = r'//*[@id=\"txt\"]/div/div[1]/div[3]'\n",
    "# 저작권 ((태그가) 두 개인 경우 cprt_attr2 주석 풀고 추가 입력) (XPATH OR CSS)\n",
    "cprt_attr1 = r'//*[@id=\"txt\"]/div/div[1]/div[4]/div/img'\n",
    "# cprt_attr2 = r'//*[@id=\"txt\"]/div/div[1]/div[3]/div/img'\n",
    "### CONFIG 4 ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "# 'CN_LINK_ADDR' 태그 # 참고 : ':nth-child(1)' 등 지워야 함  \n",
    "# 유의사항 : 전체 태그일 경우, 태그 앞에 '#' 붙어야 함\n",
    "# 전체 태그 예시 : '#txt > div > div.no-more-tables > table > tbody > tr > td.subject > a'\n",
    "# 유의사항 : 전체 태그로 해당 값을 찾지 못할 경우, 부분 태그를 사용해야 하고 이 때는 '#'을 빼야함 \n",
    "# 부분 태그 예시 : 'tr > td.subject > a'\n",
    "# 이 부분은 CSS 태그 값만 (CSS ONLY)\n",
    "### ---------------------------------------------------------------------------------------------------------------\n",
    "pcla_css = '#txt > div > div.no-more-tables > table > tbody > tr > td.subject > a'\n",
    "### CONFIG 5 ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "# 최종 생성 파일에는 입력되지 않으나, 파일명 등의 구분을 위해 크롤러 번호를 입력\n",
    "bbs_sn_num = 37388\n",
    "### ---------------------------------------------------------------------------------------------------------------\n",
    "### ---------------------------------------------------------------------------------------------------------------\n",
    "### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "### 이 밑은 CONFIG 하지 말기 (재실행의 용이성을 위해 이곳에 적어놓음)\n",
    "started_tm = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "folder_nm = 'crawler_{}_{}'.format(bbs_sn_num, started_tm)\n",
    "dt_format = '%Y-%m-%d %H:%M:%S'\n",
    "# 총 페이지 계산시 나머지\n",
    "if num_a_fin == 0:\n",
    "    rmd = 0\n",
    "else:\n",
    "    rmd = 1\n",
    "# 모을 글의 총 페이지 개수\n",
    "tot_page = (end_page - start_page) + rmd\n",
    "### Browsing 여부 ### ### ### ### ### ### ### ### ### ### ### \n",
    "options = Options()\n",
    "# 이미지 로딩 OFF (속도 개선)\n",
    "options.add_argument('--blink-settings=imagesEnabled=false')\n",
    "# 스크롤 다운 필요한 게시판의 경우 필요 # headless 상태이면 불필요\n",
    "# 게시판 크기 축소 (특정 게시판의 경우, 클릭 용이함을 위해)\n",
    "#options.add_argument(\"force-device-scale-factor=0.25\")\n",
    "# 브라우저 크기 조절\n",
    "#options.add_argument(\"--window-size=1600,1000\")\n",
    "# Headless 여부\n",
    "options.add_argument('-headless')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e6300113",
   "metadata": {},
   "outputs": [],
   "source": [
    "#contents_body > div.board_list > table > tbody > tr:nth-child(1) > td.txt_left > a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c758f75",
   "metadata": {},
   "source": [
    "### Config (click-button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d18a2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### CONFIG 1 ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "# # 데이터 수집을 시작할 페이지 번호\n",
    "# start_page = 1\n",
    "# # 마지막 페이지 번호\n",
    "# end_page = 55\n",
    "# # 마지막 페이지 글 수\n",
    "# num_a_fin = 3\n",
    "# # 한 페이지에 보여지는 글 개수\n",
    "# cnt_a = 12\n",
    "# if num_a_fin == 0:\n",
    "#     rmd = 0\n",
    "# else:\n",
    "#     rmd = 1\n",
    "# # 모을 글의 총 페이지 개수\n",
    "# tot_page = (end_page - start_page) + rmd\n",
    "# # 게시판 하단에 표시할 페이지 개수\n",
    "# page_cnt = 10\n",
    "# # 현재 페이지 (0 ~ 9)\n",
    "# cnt_cp = int(start_page % page_cnt)\n",
    "# ### ---------------------------------------------------------------------------------------------------------------\n",
    "# ### CONFIG 2 ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "# ### 시작 url\n",
    "# url_input = 'https://www.sangju.go.kr/archive/historicalRecords/index.do?menu_idx=103&main_case=1&keywd='\n",
    "# # (게시판 글 리스트에서의) 글 제목\n",
    "# article_attr1 = '#boardItem > a:nth-child({}) > div > p'\n",
    "# article_attr2 = '//*[@id=\"boardItem\"]/a[{}]/div/p'\n",
    "# # 다음 페이지 이동 버튼\n",
    "# nxt_btn_attr = '#board_paging > a.maxPagination_next'\n",
    "# # 현재 페이지 버튼\n",
    "# cpage_attr = '#board_paging > a:nth-child({})'\n",
    "# ### CONFIG 3 ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "# # 글 제목\n",
    "# ttl_attr1 = '#subPage > div.printPage > div.archive-view > div > div.archive-view__collection-title'\n",
    "# ttl_attr2 = '#subPage > div.printPage > div.archive-view > div.archive-view__title'\n",
    "# # 글 작성일\n",
    "# dt_attr1 = '#subPage > div.printPage > div.archive-view > div.archive-view__table > table > tbody > tr:nth-child(3) > td:nth-child(2)'\n",
    "# dt_attr2 = '#subPage > div.printPage > div.archive-view > div.archive-view__table > table > tbody > tr:nth-child(3) > td:nth-child(2)'\n",
    "# # 글 내용\n",
    "# cntnt_attr1 = '#subPage > div.printPage > div.archive-view > div > div.archive-view__collection-text'\n",
    "# cntnt_attr2 = '#subPage > div.printPage > div.archive-view > div.archive-view__table > table > tbody > tr:nth-child(4) > td'\n",
    "# # 파일 이름\n",
    "# fnm_attr = r'//*[@id=\"contents_body\"]/article/div[2]'\n",
    "# # 저작권\n",
    "# cprt_attr1 = '#subPage > div.printPage > div.archive-view > div.archive-view__table > table > tbody > tr:nth-child(5) > td > a > img'\n",
    "# ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "# ### CONFIG 4 ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "# # 'CN_LINK_ADDR' 태그 # 참고 : ':nth-child(1)' 등 지워야 함  \n",
    "# # 유의사항 : 전체 태그일 경우, 태그 앞에 '#' 붙어야 함\n",
    "# # 전체 태그 예시 : '#txt > div > div.no-more-tables > table > tbody > tr > td.subject > a'\n",
    "# # 유의사항 : 전체 태그로 해당 값을 찾지 못할 경우, 부분 태그를 사용해야 하고 이 때는 '#'을 빼야함 \n",
    "# # 부분 태그 예시 : 'tr > td.subject > a'\n",
    "# # 이 부분은 CSS 태그 값만 (CSS ONLY)\n",
    "# ### ---------------------------------------------------------------------------------------------------------------\n",
    "# pcla_css = '#txt > div > div.no-more-tables > table > tbody > tr > td.subject > a'\n",
    "# ### CONFIG 5 ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "# # 최종 생성 파일에는 입력되지 않으나, 파일명 등의 구분을 위해 크롤러 번호를 입력\n",
    "# bbs_sn_num = 37388\n",
    "# ### ---------------------------------------------------------------------------------------------------------------\n",
    "# ### ---------------------------------------------------------------------------------------------------------------\n",
    "# ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "# ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "# ### 이 밑은 CONFIG 하지 말기 (재실행의 용이성을 위해 이곳에 적어놓음)\n",
    "# started_tm = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "# folder_nm = 'crawler_{}_{}'.format(bbs_sn_num, started_tm)\n",
    "# dt_format = '%Y-%m-%d %H:%M:%S'\n",
    "# ### Browsing 여부\n",
    "# options = Options()\n",
    "# # 이미지 로딩 OFF (속도 개선)\n",
    "# options.add_argument('--blink-settings=imagesEnabled=false')\n",
    "# #options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko\")\n",
    "# # options.add_argument(\"--window-size=1600,1000\")\n",
    "# #options.add_argument('headless')\n",
    "# #options.add_argument(\"force-device-scale-factor=0.05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2880de8",
   "metadata": {},
   "source": [
    "### Def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4524e653",
   "metadata": {},
   "outputs": [],
   "source": [
    "### OLD\n",
    "### 전처리 함수\n",
    "def preprocess(df_input,bbs_sn):\n",
    "    ### CONFIG ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "    fp_addr = ''\n",
    "    cprt_type = ['img_opentype01', 'img_opentype02', 'img_opentype03', 'img_opentype04']\n",
    "    ptn_pdi1 = ' [0-9]{2}\\:[0-9]{2}\\:[0-9]{2}'\n",
    "    ptn_pdi2 = ' [0-9]{2}\\:[0-9]{2}'\n",
    "    ptn_fnm_adr = '\\([0-9.]{0,10}[KB|B|MB|GB]{1,2} \\/ 다운로드 .+\\/ .+\\)'\n",
    "    ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "\n",
    "    # 작성일 처리\n",
    "    for i in range(len(df_input)):\n",
    "        df_input['DT_INFO'].iloc[i] = df_input['DT_INFO'].iloc[i].replace('작성일', '')\n",
    "        # hh:mm 삭제\n",
    "        hhmm = re.findall(ptn_pdi1, df_input['DT_INFO'].iloc[i])\n",
    "        if len(hhmm) != 0:\n",
    "            df_input['DT_INFO'].iloc[i] = df_input['DT_INFO'].iloc[i].replace(hhmm[0], '')\n",
    "        hhmm2 = re.findall(ptn_pdi2, df_input['DT_INFO'].iloc[i])\n",
    "        if len(hhmm2) != 0:\n",
    "            df_input['DT_INFO'].iloc[i] = df_input['DT_INFO'].iloc[i].replace(hhmm2[0], '')\n",
    "        # yyyy/mm/dd -> yyyymmdd\n",
    "        df_input['DT_INFO'].iloc[i] = df_input['DT_INFO'].iloc[i].replace('/', '')\n",
    "        # yyyy-mm-dd -> yyyymmdd\n",
    "        df_input['DT_INFO'].iloc[i] = df_input['DT_INFO'].iloc[i].replace('-', '')\n",
    "        # yyyy.mm.dd -> yyyymmdd\n",
    "        df_input['DT_INFO'].iloc[i] = df_input['DT_INFO'].iloc[i].replace('.', '')\n",
    "\n",
    "    ## 파일명 처리\n",
    "    df_input['FILE_NM'] = df_input['FILE_NM'].fillna('')\n",
    "    for i in range(len(df_input)):\n",
    "        df_input['FILE_NM'].iloc[i] = df_input['FILE_NM'].iloc[i].replace('다운로드 미리보기', '')\n",
    "        df_input['FILE_NM'].iloc[i] = df_input['FILE_NM'].iloc[i].replace('첨부파일', '')\n",
    "\n",
    "        prnths = re.findall(ptn_fnm_adr, df_input['FILE_NM'].iloc[i])\n",
    "        if len(prnths) != 0:\n",
    "            df_input['FILE_NM'].iloc[i] = df_input['FILE_NM'].iloc[i].replace(prnths[0], '')\n",
    "            df_input['FILE_NM'].iloc[i] = df_input['FILE_NM'].iloc[i].lstrip('\\n')\n",
    "            df_input['FILE_NM'].iloc[i] = df_input['FILE_NM'].iloc[i].rstrip(' \\n')\n",
    "            df_input['FILE_NM'].iloc[i] = df_input['FILE_NM'].iloc[i].rstrip('\\n')\n",
    "            # hwp 파일 두 개 이상(추후 확장자 추가 바람)\n",
    "            if df_input['FILE_NM'].iloc[i].count('.hwp') > 1:\n",
    "                df_input['FILE_NM'].iloc[i] = df_input['FILE_NM'].iloc[i].replace('\\n', '||')\n",
    "                df_input['FILE_NM'].iloc[i] = df_input['FILE_NM'].iloc[i].rstrip('||')\n",
    "    ## 파일 스토리지 경로 입력\n",
    "    df_input['FILE_PATH'] = fp_addr\n",
    "    for i in range(len(df_input)):\n",
    "        if df_input['FILE_NM'].iloc[i] == '':\n",
    "            df_input['FILE_NM'].iloc[i] = None\n",
    "            df_input['FILE_PATH'].iloc[i] = None\n",
    "    ## 그외 파일 관련 칼럼 생성 및 입력\n",
    "    df_input['FILE_PATH_CN'] = None\n",
    "    df_input['FILE_NM_CN'] = None\n",
    "\n",
    "    # 저작권\n",
    "    df_input['CP_TYPE_NM'] = ''\n",
    "    for i in range(len(df_input)):\n",
    "        if cprt_type[0] in df_input['CP_TYPE_NM_'].iloc[i]:\n",
    "            df_input.loc[i, 'CP_TYPE_NM'] = '1'\n",
    "        elif cprt_type[1] in df_input['CP_TYPE_NM_'].iloc[i]:\n",
    "            df_input.loc[i, 'CP_TYPE_NM'] = '2'\n",
    "        elif cprt_type[2] in df_input['CP_TYPE_NM_'].iloc[i]:\n",
    "            df_input.loc[i, 'CP_TYPE_NM'] = '3'\n",
    "        elif cprt_type[3] in df_input['CP_TYPE_NM_'].iloc[i]:\n",
    "            df_input.loc[i, 'CP_TYPE_NM'] = '4'\n",
    "        else:\n",
    "            df_input.loc[i, 'CP_TYPE_NM'] = '5'\n",
    "    df_input.drop('CP_TYPE_NM_', inplace=True, axis=1)\n",
    "\n",
    "    # 시간 입력\n",
    "    df_input['CRT_DT'] = ''\n",
    "    df_input['MDFCN_DT'] = ''\n",
    "    df_input['LAST_MDFCN_DT'] = ''\n",
    "    for i in range(len(df_input)):\n",
    "        df_input.loc[i, 'CRT_DT'] = df_input['tm_stamp1'].iloc[i]\n",
    "        df_input.loc[i, 'MDFCN_DT'] = df_input['tm_stamp2'].iloc[i]\n",
    "        df_input.loc[i, 'LAST_MDFCN_DT'] = df_input['tm_stamp2'].iloc[i]\n",
    "    df_input.drop(['tm_stamp1', 'tm_stamp2'], axis=1, inplace=True)\n",
    "\n",
    "    # URL\n",
    "    df_input['ACTL_URL_ADDR'] = df_input['URL_ADDR']\n",
    "\n",
    "    # 이미지 관련 칼럼\n",
    "    df_input['IMG_PATH'] = None\n",
    "    df_input['IMG_NM'] = None\n",
    "\n",
    "    # 링크 관련 칼럼\n",
    "    df_input['FAIL_LINK_RMRK_CN'] = None\n",
    "    df_input['FAIL_LINK_STTS_SN'] = None\n",
    "    df_input['FAIL_LINK_LAST_MDFCN_DT'] = None\n",
    "\n",
    "    # 그 외 칼럼\n",
    "    df_input['STTS_SN'] = 200\n",
    "    df_input['CLCT_SN'] = None\n",
    "    df_input['RMRK_CN'] = None\n",
    "\n",
    "    # 크롤러 번호\n",
    "    df_input['BBS_SN'] = bbs_sn\n",
    "    \n",
    "# 해쉬 함수('UNQ_VL_INFO')\n",
    "def puvi_prprc(df_input):\n",
    "    df_input['UNQ_VL_INFO'] = ''\n",
    "    for i in range(len(df_input)):\n",
    "        # 간혹 'TTL' 획득시 nan 값 존재해서 각각 string 처리함\n",
    "        sha_str = str(df_input['TTL'].iloc[i]) + str(df_input['URL_ADDR'].iloc[i]) + str(df_input['CN_LINK_ADDR'].iloc[i])\n",
    "        sha_str_rst = hlb.sha512(sha_str.encode('utf-8')).hexdigest()\n",
    "        df_input.loc[i,'UNQ_VL_INFO'] = sha_str_rst\n",
    "    return df_input\n",
    "\n",
    "# table 칼럼 순서로 맞추기\n",
    "def col_organizer(df_input):\n",
    "    if len(df_input.columns) == 24:\n",
    "        df_out = df_input[['UNQ_VL_INFO', 'CN', 'FILE_PATH_CN', 'FILE_NM_CN',\n",
    "                        'RMRK_CN', 'FAIL_LINK_RMRK_CN', 'TTL', 'URL_ADDR',\n",
    "                        'CN_LINK_ADDR', 'ACTL_URL_ADDR', 'DT_INFO', 'IMG_PATH',\n",
    "                        'IMG_NM', 'FILE_PATH', 'FILE_NM', 'CP_TYPE_NM',\n",
    "                        'STTS_SN', 'LAST_MDFCN_DT', 'FAIL_LINK_STTS_SN',\n",
    "                        'FAIL_LINK_LAST_MDFCN_DT', 'CLCT_SN', 'CRT_DT', 'MDFCN_DT', 'BBS_SN']]\n",
    "    elif len(df_input.columns) == 11:\n",
    "        df_out = df_input[['UNQ_VL_INFO', 'TTL', 'LINK_ADDR', 'CN_LINK_ADDR',\n",
    "                           'DT_INFO', 'STTS_INFO', 'CLCT_SN', 'CRT_DT', 'MDFCN_DT',\n",
    "                           'BBS_SN', 'STTS_DT']]\n",
    "\n",
    "    return df_out\n",
    "\n",
    "# 'CLCT_INFO_DTL' 생성함수\n",
    "def ci_dtl_maker(df_input):\n",
    "    df_out = df_input[['UNQ_VL_INFO', 'TTL', 'URL_ADDR', 'CN_LINK_ADDR',\n",
    "                                                  'DT_INFO', 'CRT_DT', 'MDFCN_DT',\n",
    "                                                  'BBS_SN', 'LAST_MDFCN_DT']]\n",
    "    df_out = df_out.rename(\n",
    "        columns={\"URL_ADDR\": \"LINK_ADDR\", \"LAST_MDFCN_DT\": \"STTS_DT\"})\n",
    "    df_out.loc[:, 'STTS_INFO'] = 'DONE'\n",
    "    df_out['SN'] = np.NaN\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d1a7c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 게시판 마다 날짜 패턴이 다를 수 있으므로 추후 여기에 없는 패턴 발견시 추가 바람.\n",
    "# yyyy년 mm월 dd일(dow) -> yyyymmdd\n",
    "def pdi_reformer(df_input):\n",
    "    pattern_y = '[0-9]{4}년'\n",
    "    pattern_m = '[0-9]{1,2}월'\n",
    "    pattern_d = '[0-9]{1,2}일'\n",
    "    for i in range(len(df_input)):\n",
    "        str_y = re.findall(pattern_y, df_input['ENROLL_DATE'].iloc[i])\n",
    "        str_m = re.findall(pattern_m, df_input['ENROLL_DATE'].iloc[i])\n",
    "        str_d = re.findall(pattern_d, df_input['ENROLL_DATE'].iloc[i])\n",
    "        if len(str_y) != 0 and len(str_m) != 0 and len(str_d) != 0:\n",
    "            str_y = str_y[0].replace('년','')\n",
    "            str_m = str_m[0].replace('월','')\n",
    "            str_d = str_d[0].replace('일','')\n",
    "            # yyyy d m\n",
    "            if len(str_m) == 1 and len(str_d) == 1:\n",
    "                str_comb = str_y + '0' + str_m + '0' + str_d\n",
    "            # yyyy dd m\n",
    "            elif len(str_m) == 2 and len(str_d) == 1:\n",
    "                str_comb = str_y + str_m + '0' + str_d\n",
    "            # yyyy d mm\n",
    "            elif len(str_m) == 1 and len(str_d) == 2:\n",
    "                str_comb = str_y + '0' + str_m + str_d\n",
    "            # yyyy dd mm\n",
    "            elif len(str_m) == 2 and len(str_d) == 2:\n",
    "                str_comb = str_y + str_m + str_d\n",
    "            # ------------------------------------------\n",
    "            df_input.loc[i,'ENROLL_DATE'] = str_comb\n",
    "\n",
    "            \n",
    "# 속성값 차이에 따라 '작성일 ' 등의 문구가 추가될 수 있으므로, \n",
    "# 기존 전처리 함수에서 따로 기능을 분리하게 됨.\n",
    "# yyyy.mm.dd -> yyyymmdd\n",
    "# 이 코드 작성 시점까지 yyyy.m.d 등의 패턴은 발견되지 않음.\n",
    "def pdi_reformer2(df_input):\n",
    "    pattern_ymd2 = '[0-9]{4}\\.[0-9]{2}\\.[0-9]{2}'\n",
    "    str_ymd2 = re.findall(pattern_ymd2, df_input['ENROLL_DATE'].iloc[i])\n",
    "    if len(str_ymd2) != 0:\n",
    "        str_ymd2_ = str_ymd2[0].replace('.','')\n",
    "        df_input.loc[i,'ENROLL_DATE'] = str_ymd2_\n",
    "\n",
    "\n",
    "# yyyy-mm-dd -> yyyymmdd\n",
    "# 이 코드 작성 시점까지 yyyy-m-d 등의 패턴은 발견되지 않음.\n",
    "def pdi_reformer3(df_input):\n",
    "    pattern_ymd3 = '[0-9]{4}\\-[0-9]{2}\\-[0-9]{2}'\n",
    "    str_ymd3 = re.findall(pattern_ymd3, df_input['ENROLL_DATE'].iloc[i])\n",
    "    if len(str_ymd3) != 0:\n",
    "        str_ymd3_ = str_ymd3[0].replace('-','')\n",
    "        df_input.loc[i,'ENROLL_DATE'] = str_ymd3_\n",
    "\n",
    "\n",
    "# yyyy/mm/dd -> yyyymmdd\n",
    "# 이 코드 작성 시점까지 yyyy/m/d 등의 패턴은 발견되지 않음.\n",
    "def pdi_reformer4(df_input):\n",
    "    pattern_ymd4 = '[0-9]{4}\\/[0-9]{2}\\/[0-9]{2}'\n",
    "    str_ymd4 = re.findall(pattern_ymd4, df_input['ENROLL_DATE'].iloc[i])\n",
    "    if len(str_ymd4) != 0:\n",
    "        str_ymd4_ = str_ymd4[0].replace('/','')\n",
    "        df_input.loc[i,'ENROLL_DATE'] = str_ymd4_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbcfa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEW\n",
    "### 전처리 함수(엑셀)\n",
    "def preprocess_xlsx(df_input):\n",
    "    \n",
    "    cprt_type = ['img_opentype01', 'img_opentype02', 'img_opentype03', 'img_opentype04']\n",
    "    ptn_pdi1 = ' [0-9]{2}\\:[0-9]{2}\\:[0-9]{2}'\n",
    "    ptn_pdi2 = ' [0-9]{2}\\:[0-9]{2}'\n",
    "    \n",
    "    # BBS ID\n",
    "    df_input['BBS_ID'] = None\n",
    "    # CATEGORY ID\n",
    "    df_input['CATEGORY_ID'] = None\n",
    "    # CATEGORY NAME\n",
    "    df_input['CATEGORY_NAME'] = None\n",
    "    # BBS NAME\n",
    "    df_input['BBS_NAME'] = None\n",
    "    # ORG CODE\n",
    "    df_input['ORG_CODE'] = None\n",
    "    # ATC TYPE CODE\n",
    "    df_input['ATC_TYPE_CODE'] = None\n",
    "    # CAT CODE 1\n",
    "    df_input['CAT_CODE1'] = None\n",
    "    # CAT CODE 2\n",
    "    df_input['CAT_CODE2'] = None\n",
    "    \n",
    "    # ORG URL\n",
    "    df_input['ORG_URL'] = None\n",
    "    # DATA GROUP\n",
    "    df_input['DATA_GROUP'] = None\n",
    "    \n",
    "    \n",
    "     # 저작권\n",
    "    df_input['RGT_TYPE_CODE'] = ''\n",
    "    for i in range(len(df_input)):\n",
    "        if cprt_type[0] in df_input['RGT_TYPE_CODE_'].iloc[i]:\n",
    "            df_input.loc[i, 'RGT_TYPE_CODE'] = '1'\n",
    "        elif cprt_type[1] in df_input['RGT_TYPE_CODE_'].iloc[i]:\n",
    "            df_input.loc[i, 'RGT_TYPE_CODE'] = '2'\n",
    "        elif cprt_type[2] in df_input['RGT_TYPE_CODE_'].iloc[i]:\n",
    "            df_input.loc[i, 'RGT_TYPE_CODE'] = '3'\n",
    "        elif cprt_type[3] in df_input['RGT_TYPE_CODE_'].iloc[i]:\n",
    "            df_input.loc[i, 'RGT_TYPE_CODE'] = '4'\n",
    "        else:\n",
    "            df_input.loc[i, 'RGT_TYPE_CODE'] = '5'\n",
    "    df_input.drop('RGT_TYPE_CODE_', inplace=True, axis=1)\n",
    "    \n",
    "\n",
    "    # 작성일 처리\n",
    "    # -> pdi_reformer 함수들 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3a321b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7c35165",
   "metadata": {},
   "source": [
    "### Run (URL method - new) (Xpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae50cdb",
   "metadata": {},
   "source": [
    "##### URL 을 이용한 페이지 이동 (Xpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df341c00",
   "metadata": {},
   "source": [
    "##### Run All이면 Xpath, CSS 둘 중에 하나만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "26ed4f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-12 16:12:59\n",
      "1.8954157682453188\n",
      "2073 페이지 1번째 글 완료\n",
      "0.019212335066273838\n",
      "1.097933101228679\n",
      "2073 페이지 2번째 글 완료\n",
      "0.016358494319580474\n",
      "1.3688478310648258\n",
      "2023-09-12 16:13:10\n",
      "데이터 수집이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "### --------------------------------------------------------------------------------------------------------------\n",
    "print('데이터 수집을 시작합니다.')\n",
    "### 시작 시각\n",
    "start_dt = datetime.now().strftime(dt_format)\n",
    "print(start_dt)\n",
    "### ---------------------------------------\n",
    "driver = webdriver.Chrome(options=options)\n",
    "# 브라우저 창 크기 최대화\n",
    "driver.maximize_window()\n",
    "#driver.get(url_input)\n",
    "url_pg_lst, url_lst, ttl_lst, dt_lst, cntnt_lst, cprt_lst = [], [], [], [], [], []\n",
    "# 설정시의 파라미터와 실제 수집시의 파라미터가 다를 수 있으므로 예외처리\n",
    "try:\n",
    "    for i in range(tot_page):\n",
    "\n",
    "        # 페이지 클릭보다 주소를 통한 페이지 접근으로 수정...\n",
    "        url_input = str(url_str_.format(start_page+i))\n",
    "        driver.get(url_input)\n",
    "        \n",
    "        # 랜덤 시간 쉬기\n",
    "        num_rand = random.uniform(0.01, 0.99)\n",
    "        print(num_rand)\n",
    "        time.sleep(num_rand)\n",
    "        \n",
    "        ## 예외 처리\n",
    "        # 마지막 페이지일 때, 수집 페이지 개수가 2개 이상이고 마지막 글 개수가 0이 아닌 상황\n",
    "        if i == tot_page - 1 and tot_page > 1 and num_a_fin != 0:\n",
    "            cnt_a = num_a_fin\n",
    "        # 페이지 개수 1개이고 모으는 글의 개수가 한 페이지에 있어서 글 최대 개수 이하일 때\n",
    "        if tot_page == 1 and num_a_fin != 0 and num_a_fin <= cnt_a:\n",
    "            cnt_a = num_a_fin\n",
    "        # 페이지 개수 0개(start, end 같은 페이지)인데 모으는 글의 개수가 0개 이면 수집 취소\n",
    "        if tot_page == 0 and num_a_fin == 0:\n",
    "            print('수집할 데이터가 없습니다.')\n",
    "        ### 글 클릭하고 데이터 수집\n",
    "        for j in range(cnt_a):\n",
    "            # 글 제목 클릭 (마지막 페이지 제외하고 한 페이지 글 개수만큼)\n",
    "            driver.find_element(By.XPATH, article_attr.format(j + 1)).click()\n",
    "            # 그림 클릭\n",
    "            ##driver.find_element(By.XPATH, pic_attr.format(j + 1)).click()\n",
    "            # 작성일 클릭\n",
    "            ##driver.find_element(By.XPATH, dt_click_attr.format(j + 1)).click()\n",
    "            \n",
    "            ### 데이터 수집\n",
    "            # ATC_LIST_URL\n",
    "            # 페이지 URL (글마다 입력 필요)\n",
    "            url_pg_lst.append(url_input)\n",
    "        \n",
    "            # ATC_URL\n",
    "            # 글 URL\n",
    "            url_str = str(driver.current_url)\n",
    "            url_lst.append(url_str)\n",
    "            # -------------------------------------------------------\n",
    "            # ATC_TITLE\n",
    "            # 글 제목\n",
    "            try:\n",
    "                try:\n",
    "                    title = driver.find_element(By.XPATH, ttl_attr1).text\n",
    "                except:\n",
    "                    title = driver.find_element(By.XPATH, ttl_attr2).text\n",
    "            except:\n",
    "                print('제목이 획득되지 않았습니다.')\n",
    "                title = ''\n",
    "            ttl_lst.append(title)\n",
    "            ### ----------------------------------------------------------------\n",
    "            # ENROLL_DATE\n",
    "            # 작성일\n",
    "            try:\n",
    "                try:\n",
    "                    date = driver.find_element(By.XPATH, dt_att1).text\n",
    "                except:\n",
    "                    date = driver.find_element(By.XPATH, dt_attr2).text\n",
    "            except:\n",
    "                print('작성일이 획득되지 않았습니다.')\n",
    "                date = ''\n",
    "            dt_lst.append(date)\n",
    "            ### ----------------------------------------------------------------\n",
    "            # ATC_CONTENTS\n",
    "            # 내용\n",
    "            try:\n",
    "                try:\n",
    "                    cntnt = driver.find_element(By.XPATH, cntnt_attr1).text\n",
    "                except:\n",
    "                    cntnt = driver.find_element(By.XPATH, cntnt_attr2).text\n",
    "            except:\n",
    "                print('본문 내용이 획득되지 않았습니다.')\n",
    "                cntnt = ''\n",
    "            cntnt_lst.append(cntnt)\n",
    "            ### -----------------------------------------------------------------------------\n",
    "            # RGT_TYPE_CODE_\n",
    "            # 저작권 유형\n",
    "            try:\n",
    "                try:\n",
    "                    cprt = driver.find_element(By.XPATH, cprt_attr1).get_attribute('src')\n",
    "                except:\n",
    "                    cprt = driver.find_element(By.XPATH, cprt_attr2).get_attribute('src')\n",
    "            except:\n",
    "                print('저작권 유형이 획득되지 않았습니다.')\n",
    "                cprt = ''\n",
    "            cprt_lst.append(cprt)\n",
    "            # --------------------------------------------------------------------------------\n",
    "            # 완료 표시\n",
    "            print('{} 페이지 {}번째 글 완료'.format((i + start_page), (j + 1)))\n",
    "            # 랜덤 시간 쉬기\n",
    "            num_rand = random.uniform(0.01, 0.09)\n",
    "            print(num_rand)\n",
    "            time.sleep(num_rand)\n",
    "\n",
    "            # 뒤로가기 \n",
    "            ##driver.back()\n",
    "            # 뒤로가기 대신 url로 게시판 다시 호출(headless를 사용하기 위함)\n",
    "            url_input = str(url_str_.format(start_page+i))\n",
    "            driver.get(url_input)\n",
    "            \n",
    "            # 랜덤 시간 쉬기\n",
    "            num_rand = random.uniform(0.71, 1.59)\n",
    "            print(num_rand)\n",
    "            time.sleep(num_rand)\n",
    "            \n",
    "        if i == tot_page - 1:\n",
    "            ### 종료 시각\n",
    "            end_dt = datetime.now().strftime(dt_format)\n",
    "            print(end_dt)\n",
    "            ### 종료\n",
    "            driver.quit()\n",
    "            \n",
    "            print('데이터 수집이 완료되었습니다.')\n",
    "            \n",
    "except:\n",
    "    print('파라미터 설정을 다시 확인해 주세요.')\n",
    "    ### 종료 시각\n",
    "    end_dt = datetime.now().strftime(dt_format)\n",
    "    print(end_dt)\n",
    "    ### 종료\n",
    "    driver.quit()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b13e5",
   "metadata": {},
   "source": [
    "### Run (URL method - new) (CSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562785d6",
   "metadata": {},
   "source": [
    "##### URL 을 이용한 페이지 이동 (CSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ad88c6",
   "metadata": {},
   "source": [
    "##### Run All이면 Xpath, CSS 둘 중에 하나만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1d9c7184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### --------------------------------------------------------------------------------------------------------------\n",
    "# print('데이터 수집을 시작합니다.')\n",
    "# ### 시작 시각\n",
    "# start_dt = datetime.now().strftime(dt_format)\n",
    "# print(start_dt)\n",
    "# ### ---------------------------------------\n",
    "# driver = webdriver.Chrome(options=options)\n",
    "# driver.maximize_window()\n",
    "# #driver.get(url_input)\n",
    "# url_pg_lst, url_lst, ttl_lst, dt_lst, cntnt_lst, cprt_lst = [], [], [], [], [], []\n",
    "# # 설정시의 파라미터와 실제 수집시의 파라미터가 다를 수 있으므로 예외처리\n",
    "# try:\n",
    "#     for i in range(tot_page):\n",
    "\n",
    "#         # 페이지 클릭보다 주소를 통한 페이지 접근으로 수정...\n",
    "#         url_input = str(url_str_.format(start_page+i))\n",
    "#         driver.get(url_input)\n",
    "        \n",
    "#         # 랜덤 시간 쉬기\n",
    "#         num_rand = random.uniform(0.01, 0.99)\n",
    "#         print(num_rand)\n",
    "#         time.sleep(num_rand)\n",
    "        \n",
    "#         ## 예외 처리\n",
    "#         # 마지막 페이지일 때, 수집 페이지 개수가 2개 이상이고 마지막 글 개수가 0이 아닌 상황\n",
    "#         if i == tot_page - 1 and tot_page > 1 and num_a_fin != 0:\n",
    "#             cnt_a = num_a_fin\n",
    "#         # 페이지 개수 1개이고 모으는 글의 개수가 한 페이지에 있어서 글 최대 개수 이하일 때\n",
    "#         if tot_page == 1 and num_a_fin != 0 and num_a_fin <= cnt_a:\n",
    "#             cnt_a = num_a_fin\n",
    "#         # 페이지 개수 0개(start, end 같은 페이지)인데 모으는 글의 개수가 0개 이면 수집 취소\n",
    "#         if tot_page == 0 and num_a_fin == 0:\n",
    "#             print('수집할 데이터가 없습니다.')\n",
    "#         ### 글 클릭하고 데이터 수집\n",
    "#         for j in range(cnt_a):\n",
    "#             # 글 제목 클릭 (마지막 페이지 제외하고 10개씩)\n",
    "#             driver.find_element(By.CSS_SELECTOR, article_attr.format(j + 1)).click()\n",
    "#             # 그림 클릭\n",
    "#             ##driver.find_element(By.CSS_SELECTOR, pic_attr.format(j + 1)).click()\n",
    "#             # 작성일 클릭\n",
    "#             ##driver.find_element(By.CSS_SELECTOR, dt_click_attr.format(j + 1)).click()\n",
    "            \n",
    "#             ### 데이터 수집\n",
    "#             # ATC_LIST_URL\n",
    "#             # 페이지 URL (글마다 입력 필요)\n",
    "#             url_pg_lst.append(url_input)\n",
    "        \n",
    "#             # ATC_URL\n",
    "#             # 글 URL\n",
    "#             url_str = str(driver.current_url)\n",
    "#             url_lst.append(url_str)\n",
    "#             # -------------------------------------------------------\n",
    "#             # ATC_TITLE\n",
    "#             # 글 제목\n",
    "#             try:\n",
    "#                 try:\n",
    "#                     title = driver.find_element(By.CSS_SELECTOR, ttl_attr1).text\n",
    "#                 except:\n",
    "#                     title = driver.find_element(By.CSS_SELECTOR, ttl_attr2).text\n",
    "#             except:\n",
    "#                 print('제목이 획득되지 않았습니다.')\n",
    "#                 title = ''\n",
    "#             ttl_lst.append(title)\n",
    "#             ### ----------------------------------------------------------------\n",
    "#             # ENROLL_DATE\n",
    "#             # 작성일\n",
    "#             try:\n",
    "#                 try:\n",
    "#                     date = driver.find_element(By.CSS_SELECTOR, dt_att1).text\n",
    "#                 except:\n",
    "#                     date = driver.find_element(By.CSS_SELECTOR, dt_attr2).text\n",
    "#             except:\n",
    "#                 print('작성일이 획득되지 않았습니다.')\n",
    "#                 date = ''\n",
    "#             dt_lst.append(date)\n",
    "#             ### ----------------------------------------------------------------\n",
    "#             # ATC_CONTENTS\n",
    "#             # 내용\n",
    "#             try:\n",
    "#                 try:\n",
    "#                     cntnt = driver.find_element(By.CSS_SELECTOR, cntnt_attr1).text\n",
    "#                 except:\n",
    "#                     cntnt = driver.find_element(By.CSS_SELECTOR, cntnt_attr2).text\n",
    "#             except:\n",
    "#                 print('본문 내용이 획득되지 않았습니다.')\n",
    "#                 cntnt = ''\n",
    "#             cntnt_lst.append(cntnt)\n",
    "#             ### -----------------------------------------------------------------------------\n",
    "#             # RGT_TYPE_CODE_\n",
    "#             # 저작권 유형\n",
    "#             try:\n",
    "#                 try:\n",
    "#                     cprt = driver.find_element(By.CSS_SELECTOR, cprt_attr1).get_attribute('src')\n",
    "#                 except:\n",
    "#                     cprt = driver.find_element(By.CSS_SELECTOR, cprt_attr2).get_attribute('src')\n",
    "#             except:\n",
    "#                 print('저작권 유형이 획득되지 않았습니다.')\n",
    "#                 cprt = ''\n",
    "#             cprt_lst.append(cprt)\n",
    "#             # --------------------------------------------------------------------------------\n",
    "#             # 완료 표시\n",
    "#             print('{} 페이지 {}번째 글 완료'.format((i + start_page), (j + 1)))\n",
    "#             # 랜덤 시간 쉬기\n",
    "#             num_rand = random.uniform(0.01, 0.09)\n",
    "#             print(num_rand)\n",
    "#             time.sleep(num_rand)\n",
    "\n",
    "#             # 뒤로가기 \n",
    "#             ##driver.back()\n",
    "#             # 뒤로가기 대신 url로 게시판 다시 호출(headless를 사용하기 위함)\n",
    "#             url_input = str(url_str_.format(start_page+i))\n",
    "#             driver.get(url_input)\n",
    "            \n",
    "#             # 랜덤 시간 쉬기\n",
    "#             num_rand = random.uniform(0.71, 1.59)\n",
    "#             print(num_rand)\n",
    "#             time.sleep(num_rand)\n",
    "            \n",
    "#         if i == tot_page - 1:\n",
    "#             ### 종료 시각\n",
    "#             end_dt = datetime.now().strftime(dt_format)\n",
    "#             print(end_dt)\n",
    "#             ### 종료\n",
    "#             driver.quit()\n",
    "            \n",
    "#             print('데이터 수집이 완료되었습니다.')\n",
    "            \n",
    "# except:\n",
    "#     print('파라미터 설정을 다시 확인해 주세요.')\n",
    "#     ### 종료 시각\n",
    "#     end_dt = datetime.now().strftime(dt_format)\n",
    "#     print(end_dt)\n",
    "#     ### 종료\n",
    "#     driver.quit()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0c4fda",
   "metadata": {},
   "source": [
    "### Run (URL method - old) (Xpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f5e743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Browsing 여부 ### ### ### ### ### ### ### ### ### ### ### \n",
    "# options = Options()\n",
    "# # 이미지 로딩 OFF (속도 개선)\n",
    "# options.add_argument('--blink-settings=imagesEnabled=false')\n",
    "# #options.add_argument(\"--window-size=1600,1000\")\n",
    "# options.add_argument('-headless')\n",
    "# ### --------------------------------------------------------------------------------------------------------------\n",
    "# ### 시작 시각\n",
    "# start_dt = datetime.now().strftime(dt_format)\n",
    "# print(start_dt)\n",
    "# ### ---------------------------------------\n",
    "# driver = webdriver.Chrome(options=options)\n",
    "# driver.maximize_window()\n",
    "# #driver.get(url_input)\n",
    " \n",
    "# url_lst, ttl_lst, dt_lst, cntnt_lst, fnm_lst, cprt_lst, tm_stmp1, tm_stmp2 = [], [], [], [], [], [], [], []\n",
    "# # 설정시의 파라미터와 실제 수집시의 파라미터가 다를 수 있으므로 예외처리\n",
    "# try:\n",
    "#     for i in range(tot_page):\n",
    "\n",
    "#         # 페이지 클릭보다 주소를 통한 페이지 접근으로 수정...\n",
    "#         url_input = str(url_str_.format(start_page+i))\n",
    "#         driver.get(url_input)\n",
    "        \n",
    "#         # 사람처럼 보이기 # 반복 횟수 많아질 때 sleep 길게해 줄 필요있음(10,000개 까진 필요없는 것 같음)\n",
    "#         num_tst = random.uniform(0.01, 0.99)\n",
    "#         print(num_tst)\n",
    "#         time.sleep(num_tst)\n",
    "#         ### 글 클릭하고 데이터 수집\n",
    "#         ## 예외 처리\n",
    "#         # 마지막 페이지일 때, 수집 페이지 개수가 2개 이상이고 마지막 글 개수가 0이 아닌 상황\n",
    "#         if i == tot_page - 1 and tot_page > 1 and num_a_fin != 0:\n",
    "#             cnt_a = num_a_fin\n",
    "#         # 페이지 개수 1개이고 모으는 글의 개수가 한 페이지에 있어서 글 최대 개수 이하일 때\n",
    "#         if tot_page == 1 and num_a_fin != 0 and num_a_fin <= cnt_a:\n",
    "#             cnt_a = num_a_fin\n",
    "#         # 페이지 개수 0개(start, end 같은 페이지)인데 모으는 글의 개수가 0개 이면 수집 취소\n",
    "#         if tot_page == 0 and num_a_fin == 0:\n",
    "#             print('수집할 데이터가 없습니다.')\n",
    "#             df_out = pd.DataFrame(np.column_stack([url_lst, ttl_lst, dt_lst, cntnt_lst, fnm_lst, cprt_lst, tm_stmp1, tm_stmp2]),\n",
    "#                     columns=['URL_ADDR', 'TTL', 'DT_INFO', 'CN', 'FILE_NM', 'CP_TYPE_NM_','tm_stamp1', 'tm_stamp2'])\n",
    "#         for j in range(cnt_a):\n",
    "#             # 글 클릭 (마지막 페이지 제외하고 10개씩)\n",
    "#             driver.find_element(By.XPATH, article_attr.format(j + 1)).click()\n",
    "#             #driver.find_element(By.XPATH, pic_attr.format(j + 1)).click()\n",
    "#             #driver.find_element(By.XPATH, dt_click_attr.format(j + 1)).click()\n",
    "#             ### 데이터 수집\n",
    "#             # URL\n",
    "#             url_str = str(driver.current_url)\n",
    "#             url_lst.append(url_str)\n",
    "#             # -------------------------------------------------------\n",
    "#             # time stamp 1\n",
    "#             stmp1 = datetime.now().strftime(dt_format)\n",
    "#             tm_stmp1.append(stmp1)\n",
    "#             # -----------------------------------------------------------------\n",
    "#             # 글 제목\n",
    "#             title = driver.find_element(By.XPATH, ttl_attr).text\n",
    "#             #print(title)\n",
    "#             if len(title) == 0:\n",
    "#                 ttl_lst.append('')\n",
    "#             else:\n",
    "#                 ttl_lst.append(title)\n",
    "#             ### ----------------------------------------------------------------\n",
    "#             # 작성일\n",
    "#             date = driver.find_element(By.XPATH, dt_attr).text\n",
    "#             if len(date) == 0:\n",
    "#                 dt_lst.append('')\n",
    "#             else:\n",
    "#                 dt_lst.append(date)\n",
    "#             ### ----------------------------------------------------------------\n",
    "#             # 내용\n",
    "#             try:\n",
    "#                 try:\n",
    "#                     cntnt1 = driver.find_element(By.XPATH, cntnt_attr1).text\n",
    "#                     cntnt = cntnt1\n",
    "#                 except:\n",
    "#                     cntnt2 = driver.find_element(By.XPATH, cntnt_attr2).text\n",
    "#                     cntnt = cntnt2\n",
    "#             except:\n",
    "#                 print('본문 내용이 획득되지 않았습니다.')\n",
    "#                 cntnt = ''\n",
    "#             cntnt_lst.append(cntnt)\n",
    "#             ### ----------------------------------------------------------------\n",
    "#             # 파일명\n",
    "#             file_nm = driver.find_elements(By.XPATH, fnm_attr)\n",
    "#             if len(file_nm) == 0:\n",
    "#                 print('파일 다운로드 없음')\n",
    "#                 fnm_lst.append('')\n",
    "#             else:\n",
    "#                 file__ = []\n",
    "#                 for file_ in file_nm:\n",
    "#                     ##print(file_.text)\n",
    "#                     file__.append(file_.text)\n",
    "#                 fnm_lst.append(file__[0])\n",
    "#             ### -----------------------------------------------------------------------------\n",
    "#             # 저작권 유형\n",
    "#             try:\n",
    "#                 try:\n",
    "#                     cprt1 = driver.find_element(By.XPATH, cprt_attr1).get_attribute('src')\n",
    "#                     cprt = cprt1\n",
    "#                 except:\n",
    "#                     cprt2 = driver.find_element(By.XPATH, cprt_attr2).get_attribute('src')\n",
    "#                     cprt = cprt2\n",
    "#             except:\n",
    "#                 print('저작권 유형이 획득되지 않았습니다.')\n",
    "#                 #print('cprt1 except : {}'.format(cprt1))\n",
    "#                 #print('cprt2 except : {}'.format(cprt2))\n",
    "#                 cprt = ''\n",
    "#             cprt_lst.append(cprt)\n",
    "#             # --------------------------------------------------------------------------------\n",
    "#             # 로깅\n",
    "#             print('{} 페이지 {}번째 글 완료'.format((i + start_page), (j + 1)))\n",
    "#             # 사람처럼 보이기 # 반복 횟수 많아질 때 sleep 길게해 줄 필요있음(10,000개 까진 필요없는 것 같음)\n",
    "#             num_tst = random.uniform(0.01, 0.09)\n",
    "#             print(num_tst)\n",
    "#             time.sleep(num_tst)\n",
    "\n",
    "#             # time stamp 2\n",
    "#             stmp2 = datetime.now().strftime(dt_format)\n",
    "#             tm_stmp2.append(stmp2)\n",
    "\n",
    "#             # 뒤로가기 # 뒤로가기 대신 url로 게시판 다시 호출(headless를 사용하기 위함)\n",
    "#             #driver.back()\n",
    "#             url_input = str(url_str_.format(start_page+i))\n",
    "#             driver.get(url_input)\n",
    "            \n",
    "#             # 사람처럼 보이기 # 반복 횟수 많아질 때 sleep 길게해 줄 필요있음(10,000개 까진 필요없는 것 같음)\n",
    "#             num_tst = random.uniform(0.71, 1.59)\n",
    "#             print(num_tst)\n",
    "#             time.sleep(num_tst)\n",
    "            \n",
    "#         if i == tot_page - 1:\n",
    "#             ### 종료 시각\n",
    "#             end_dt = datetime.now().strftime(dt_format)\n",
    "#             print(end_dt)\n",
    "#             ### 종료\n",
    "#             driver.quit()\n",
    "            \n",
    "#             print('데이터 수집이 완료되었습니다.')\n",
    "            \n",
    "#             ## df\n",
    "# #             df_out = pd.DataFrame(np.column_stack([url_lst, ttl_lst, dt_lst, cntnt_lst, fnm_lst, cprt_lst, tm_stmp1, tm_stmp2]),\n",
    "# #                 columns=['URL_ADDR', 'TTL', 'DT_INFO', 'CN', 'FILE_NM','CP_TYPE_NM_', 'tm_stamp1','tm_stamp2'])\n",
    "# except:\n",
    "#     print('파라미터 설정을 다시 확인해 주세요.')\n",
    "#     ### 종료 시각\n",
    "#     end_dt = datetime.now().strftime(dt_format)\n",
    "#     print(end_dt)\n",
    "#     ### 종료\n",
    "#     driver.quit()\n",
    "#     ### df\n",
    "# #     df_out = pd.DataFrame(np.column_stack([url_lst, ttl_lst, dt_lst, cntnt_lst, fnm_lst, cprt_lst, tm_stmp1, tm_stmp2]),\n",
    "# #             columns=['URL_ADDR', 'TTL', 'DT_INFO', 'CN', 'FILE_NM','CP_TYPE_NM_', 'tm_stamp1','tm_stamp2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabd567d",
   "metadata": {},
   "source": [
    "### Run (URL method - old) (CSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2010fb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Browsing 여부 ### ### ### ### ### ### ### ### ### ### ### \n",
    "# options = Options()\n",
    "# # 이미지 로딩 OFF (속도 개선)\n",
    "# options.add_argument('--blink-settings=imagesEnabled=false')\n",
    "# #options.add_argument(\"--window-size=1600,1000\")\n",
    "# #options.add_argument('headless')\n",
    "# ### --------------------------------------------------------------------------------------------------------------\n",
    "# ### 시작 시각\n",
    "# start_dt = datetime.now().strftime(dt_format)\n",
    "# print(start_dt)\n",
    "# ### ---------------------------------------\n",
    "# driver = webdriver.Chrome(options=options)\n",
    "# driver.maximize_window()\n",
    "# #driver.get(url_input)\n",
    " \n",
    "# url_lst, ttl_lst, dt_lst, cntnt_lst, fnm_lst, cprt_lst, tm_stmp1, tm_stmp2 = [], [], [], [], [], [], [], []\n",
    "# # 설정시의 파라미터와 실제 수집시의 파라미터가 다를 수 있으므로 예외처리\n",
    "# try:\n",
    "#     for i in range(tot_page):\n",
    "\n",
    "#         # 페이지 클릭보다 주소를 통한 페이지 접근으로 수정...\n",
    "#         url_input = str(url_str_.format(start_page+i))\n",
    "#         driver.get(url_input)\n",
    "        \n",
    "#         # 사람처럼 보이기 # 반복 횟수 많아질 때 sleep 길게해 줄 필요있음(10,000개 까진 필요없는 것 같음)\n",
    "#         num_tst = random.uniform(1.01, 1.99)\n",
    "#         print(num_tst)\n",
    "#         time.sleep(num_tst)\n",
    "\n",
    "#         ### 글 클릭하고 데이터 수집\n",
    "#         ## 예외 처리\n",
    "#         # 마지막 페이지일 때, 수집 페이지 개수가 2개 이상이고 마지막 글 개수가 0이 아닌 상황\n",
    "#         if i == tot_page - 1 and tot_page > 1 and num_a_fin != 0:\n",
    "#             cnt_a = num_a_fin\n",
    "#         # 페이지 개수 1개이고 모으는 글의 개수가 한 페이지에 있어서 글 최대 개수 이하일 때\n",
    "#         if tot_page == 1 and num_a_fin != 0 and num_a_fin <= cnt_a:\n",
    "#             cnt_a = num_a_fin\n",
    "#         # 페이지 개수 0개(start, end 같은 페이지)인데 모으는 글의 개수가 0개 이면 수집 취소\n",
    "#         if tot_page == 0 and num_a_fin == 0:\n",
    "#             print('수집할 데이터가 없습니다.')\n",
    "#             df_out = pd.DataFrame(np.column_stack([url_lst, ttl_lst, dt_lst, cntnt_lst, fnm_lst, cprt_lst, tm_stmp1, tm_stmp2]),\n",
    "#                     columns=['URL_ADDR', 'TTL', 'DT_INFO', 'CN', 'FILE_NM', 'CP_TYPE_NM_','tm_stamp1', 'tm_stamp2'])\n",
    "#         for j in range(cnt_a):\n",
    "#             # 글 클릭 (마지막 페이지 제외하고 10개씩)\n",
    "#             driver.find_element(By.CSS_SELECTOR, article_attr.format(j + 1)).click()\n",
    "#             #driver.find_element(By.CSS_SELECTOR, pic_attr.format(j + 1)).click()\n",
    "#             #driver.find_element(By.CSS_SELECTOR, dt_click_attr.format(j + 1)).click()\n",
    "#             ### 데이터 수집\n",
    "#             # URL\n",
    "#             url_str = str(driver.current_url)\n",
    "#             url_lst.append(url_str)\n",
    "#             # -------------------------------------------------------\n",
    "#             # time stamp 1\n",
    "#             stmp1 = datetime.now().strftime(dt_format)\n",
    "#             tm_stmp1.append(stmp1)\n",
    "#             # -----------------------------------------------------------------\n",
    "#             # 글 제목\n",
    "#             title = driver.find_element(By.CSS_SELECTOR, ttl_attr).text\n",
    "#             #print(title)\n",
    "#             if len(title) == 0:\n",
    "#                 ttl_lst.append('')\n",
    "#             else:\n",
    "#                 ttl_lst.append(title)\n",
    "#             ### ----------------------------------------------------------------\n",
    "#             # 작성일\n",
    "#             date = driver.find_element(By.CSS_SELECTOR, dt_attr).text\n",
    "#             if len(date) == 0:\n",
    "#                 dt_lst.append('')\n",
    "#             else:\n",
    "#                 dt_lst.append(date)\n",
    "#             ### ----------------------------------------------------------------\n",
    "#             # 내용\n",
    "#             try:\n",
    "#                 try:\n",
    "#                     cntnt1 = driver.find_element(By.CSS_SELECTOR, cntnt_attr1).text\n",
    "#                     cntnt = cntnt1\n",
    "#                 except:\n",
    "#                     cntnt2 = driver.find_element(By.CSS_SELECTOR, cntnt_attr2).text\n",
    "#                     cntnt = cntnt2\n",
    "#             except:\n",
    "#                 print('본문 내용이 획득되지 않았습니다.')\n",
    "#                 cntnt = ''\n",
    "#             cntnt_lst.append(cntnt)\n",
    "#             ### ----------------------------------------------------------------\n",
    "#             # 파일명\n",
    "#             file_nm = driver.find_elements(By.CSS_SELECTOR, fnm_attr)\n",
    "#             if len(file_nm) == 0:\n",
    "#                 print('파일 다운로드 없음')\n",
    "#                 fnm_lst.append('')\n",
    "#             else:\n",
    "#                 file__ = []\n",
    "#                 for file_ in file_nm:\n",
    "#                     ##print(file_.text)\n",
    "#                     file__.append(file_.text)\n",
    "#                 fnm_lst.append(file__[0])\n",
    "#             ### -----------------------------------------------------------------------------\n",
    "#             # 저작권 유형\n",
    "#             try:\n",
    "#                 try:\n",
    "#                     cprt1 = driver.find_element(By.CSS_SELECTOR, cprt_attr1).get_attribute('src')\n",
    "#                     cprt = cprt1\n",
    "#                 except:\n",
    "#                     cprt2 = driver.find_element(By.CSS_SELECTOR, cprt_attr2).get_attribute('src')\n",
    "#                     cprt = cprt2\n",
    "#             except:\n",
    "#                 print('저작권 유형이 획득되지 않았습니다.')\n",
    "#                 #print('cprt1 except : {}'.format(cprt1))\n",
    "#                 #print('cprt2 except : {}'.format(cprt2))\n",
    "#                 cprt = ''\n",
    "#             cprt_lst.append(cprt)\n",
    "#             # --------------------------------------------------------------------------------\n",
    "#             # 로깅\n",
    "#             print('{} 페이지 {}번째 글 완료'.format((i + start_page), (j + 1)))\n",
    "#             # 사람처럼 보이기 # 반복 횟수 많아질 때 sleep 길게해 줄 필요있음(10,000개 까진 필요없는 것 같음)\n",
    "#             num_tst = random.uniform(0.01, 0.09)\n",
    "#             print(num_tst)\n",
    "#             time.sleep(num_tst)\n",
    "\n",
    "#             # time stamp 2\n",
    "#             stmp2 = datetime.now().strftime(dt_format)\n",
    "#             tm_stmp2.append(stmp2)\n",
    "\n",
    "#             # 뒤로가기\n",
    "#             driver.back()\n",
    "#             # 사람처럼 보이기 # 반복 횟수 많아질 때 sleep 길게해 줄 필요있음(10,000개 까진 필요없는 것 같음)\n",
    "#             num_tst = random.uniform(1.01, 2.09)\n",
    "#             print(num_tst)\n",
    "#             time.sleep(num_tst)\n",
    "            \n",
    "#         if i == tot_page - 1:\n",
    "#             ### 종료 시각\n",
    "#             end_dt = datetime.now().strftime(dt_format)\n",
    "#             print(end_dt)\n",
    "#             ### 종료\n",
    "#             driver.quit()\n",
    "            \n",
    "#             print('데이터 수집이 완료되었습니다.')\n",
    "            \n",
    "#             ## df\n",
    "# #             df_out = pd.DataFrame(np.column_stack([url_lst, ttl_lst, dt_lst, cntnt_lst, fnm_lst, cprt_lst, tm_stmp1, tm_stmp2]),\n",
    "# #                 columns=['URL_ADDR', 'TTL', 'DT_INFO', 'CN', 'FILE_NM','CP_TYPE_NM_', 'tm_stamp1','tm_stamp2'])\n",
    "# except:\n",
    "#     print('파라미터 설정을 다시 확인해 주세요.')\n",
    "#     ### 종료 시각\n",
    "#     end_dt = datetime.now().strftime(dt_format)\n",
    "#     print(end_dt)\n",
    "#     ### 종료\n",
    "#     driver.quit()\n",
    "#     ### df\n",
    "# #     df_out = pd.DataFrame(np.column_stack([url_lst, ttl_lst, dt_lst, cntnt_lst, fnm_lst, cprt_lst, tm_stmp1, tm_stmp2]),\n",
    "# #             columns=['URL_ADDR', 'TTL', 'DT_INFO', 'CN', 'FILE_NM','CP_TYPE_NM_', 'tm_stamp1','tm_stamp2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2784074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f96492e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36dd13ef",
   "metadata": {},
   "source": [
    "### Run (Click-Button method) (Xpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8716d58e",
   "metadata": {},
   "source": [
    "##### 버튼 클릭을 통한 페이지 이동 (URL 주소가 불규칙하게 변형될 때 사용 권장)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c643e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### --------------------------------------------------------------------------------------------------------------\n",
    "# ### 시작 시각\n",
    "# start_dt = datetime.now().strftime(dt_format)\n",
    "# print(start_dt)\n",
    "# ### ---------------------------------------\n",
    "# driver = webdriver.Chrome(options=options)\n",
    "# #driver = webdriver.Firefox(options=options)\n",
    "# driver.maximize_window()\n",
    "# #driver.execute_script(\"document.body.style.MozTransform = 'scale(0.1)'\")\n",
    "# driver.get(url_input)\n",
    "# time.sleep(5)\n",
    "\n",
    "# url_lst, ttl_lst, dt_lst, cntnt_lst, fnm_lst, cprt_lst, tm_stmp1, tm_stmp2 = [], [], [], [], [], [], [], []\n",
    "# # 설정시의 파라미터와 실제 수집시의 파라미터가 다를 수 있으므로 예외처리\n",
    "# try:\n",
    "#     for i in range(tot_page):\n",
    "\n",
    "#         ### 페이지 클릭\n",
    "#         if cnt_cp == 0:\n",
    "#             cnt_cp = page_cnt\n",
    "     \n",
    "#         # 해당 페이지 클릭 # 현재 페이지가 굵게 표시되고 클릭이 안 되는 게시판도 있으므로 기본적으로는 주석처리함.\n",
    "#         #driver.find_element(By.XPATH, cpage_attr.format(cnt_cp)).click()\n",
    "        \n",
    "#         #driver.find_element(By.XPATH, cpage_attr).click()\n",
    "#         # 사람처럼 보이기 # 반복 횟수 많아질 때 sleep 길게해 줄 필요있음(10,000개 까진 필요없는 것 같음)\n",
    "#         num_tst = random.uniform(0.01, 0.09)\n",
    "#         print(num_tst)\n",
    "#         time.sleep(num_tst)\n",
    "\n",
    "#         ### 글 클릭하고 데이터 수집\n",
    "#         ## 예외 처리\n",
    "#         # 마지막 페이지일 때, 수집 페이지 개수가 2개 이상이고 마지막 글 개수가 0이 아닌 상황\n",
    "#         if i == tot_page - 1 and tot_page > 1 and num_a_fin != 0:\n",
    "#             cnt_a = num_a_fin\n",
    "#         # 페이지 개수 1개이고 모으는 글의 개수가 한 페이지에 있어서 글 최대 개수 이하일 때\n",
    "#         if tot_page == 1 and num_a_fin != 0 and num_a_fin <= cnt_a:\n",
    "#             cnt_a = num_a_fin\n",
    "#         # 페이지 개수 0개(start, end 같은 페이지)인데 모으는 글의 개수가 0개 이면 수집 취소\n",
    "#         if tot_page == 0 and num_a_fin == 0:\n",
    "#             print('수집할 데이터가 없습니다.')\n",
    "#             df_out = pd.DataFrame(np.column_stack([url_lst, ttl_lst, dt_lst, cntnt_lst, fnm_lst, cprt_lst, tm_stmp1, tm_stmp2]),\n",
    "#                     columns=['URL_ADDR', 'TTL', 'DT_INFO', 'CN', 'FILE_NM', 'CP_TYPE_NM_','tm_stamp1', 'tm_stamp2'])\n",
    "#         for j in range(cnt_a):\n",
    "#             # 글 클릭 (마지막 페이지 제외하고 10개씩)\n",
    "          \n",
    "#             #print(article_attr.format(j + 1))\n",
    "#             #prev_height = driver.execute_script('return document.body.scrollHeight')\n",
    "#             #print('prev height : {}'.format(prev_height))\n",
    "#             # 게시판 사이즈가 클 경우 스크롤 다운 등의 동작 추가도 필요(항시 해당되는 것은 아니므로 주석처리됨)\n",
    "#             #driver.execute_script('window.scrollTo(0,340)')\n",
    "           \n",
    "#             driver.find_element(By.XPATH, article_attr1.format(j + 1)).click()\n",
    "#             #driver.find_element(By.XPATH, r'//*[@id=\"boardItem\"]/a[{}]'.format(j+1)).click()\n",
    "#             #driver.find_element(By.XPATH, '#boardItem > a:nth-child({})'.format(j+1)).click()\n",
    "#             #'//*[@id=\"boardItem\"]/a[1]'\n",
    "#             # 글 클릭에 드는 시간에 비해 게시글 로딩 시간이 길 경우 sleep 주는 것이 필요.\n",
    "#             #time.sleep(5)\n",
    "#             #time.sleep(10)\n",
    "#             # 글 제목이 없을 경우, 사진 혹은 작성일 클릭을 권장\n",
    "#             # driver.find_element(By.XPATH, pic_attr.format(j + 1)).click()\n",
    "#             #driver.find_element(By.XPATH, dt_click_attr.format(j + 1)).click()\n",
    "#             ### 데이터 수집\n",
    "#             # URL\n",
    "#             url_str = str(driver.current_url)\n",
    "#             url_lst.append(url_str)\n",
    "#             # -------------------------------------------------------\n",
    "#             # time stamp 1\n",
    "#             stmp1 = datetime.now().strftime(dt_format)\n",
    "#             tm_stmp1.append(stmp1)\n",
    "#             # -----------------------------------------------------------------\n",
    "#             # 글 제목\n",
    "#             try:\n",
    "#                 try:\n",
    "#                     title = driver.find_element(By.XPATH, ttl_attr1).text\n",
    "#                 except:\n",
    "#                     title = driver.find_element(By.XPATH, ttl_attr2).text\n",
    "#             except:\n",
    "#                 print('제목이 획득되지 않았습니다.')\n",
    "#                 title = ''\n",
    "#             ttl_lst.append(title)\n",
    "#             # 확인용 제목 출력\n",
    "#             #print('title : {}'.format(title))\n",
    "#             # -----------------------------------------------------------------\n",
    "#             # 작성일\n",
    "#             try:\n",
    "#                 try:\n",
    "#                     date = driver.find_element(By.XPATH, dt_attr1).text\n",
    "#                 except:\n",
    "#                     date = driver.find_element(By.XPATH, dt_attr2).text\n",
    "#             except:\n",
    "#                 print('작성일이 획득되지 않았습니다.')\n",
    "#                 date = ''\n",
    "#             dt_lst.append(date)\n",
    "#             # -----------------------------------------------------------------\n",
    "#             # 내용\n",
    "#             try:\n",
    "#                 try:\n",
    "#                     cntnt = driver.find_element(By.XPATH, cntnt_attr1).text\n",
    "#                 except:\n",
    "#                     cntnt = driver.find_element(By.XPATH, cntnt_attr2).text\n",
    "#             except:\n",
    "#                 print('본문 내용이 획득되지 않았습니다.')\n",
    "#                 cntnt = ''\n",
    "#             cntnt_lst.append(cntnt)\n",
    "#             ### ----------------------------------------------------------------\n",
    "#             file_nm = driver.find_elements(By.XPATH, fnm_attr)\n",
    "#             if len(file_nm) == 0:\n",
    "#                 print('파일 다운로드 없음')\n",
    "#                 fnm_lst.append('')\n",
    "#             else:\n",
    "#                 file__ = []\n",
    "#                 for file_ in file_nm:\n",
    "#                     ##print(file_.text)\n",
    "#                     file__.append(file_.text)\n",
    "#                 fnm_lst.append(file__[0])\n",
    "#             # 파일 다운로드 태그가 구현이 안된 게시판의 경우 위 파일명 획득 코드를 주석처리 하고\n",
    "#             # 밑의 '' 빈 스트링 값을 추가하는 코드의 주석을 풀기 바람\n",
    "#             #fnm_lst.append('')\n",
    "#             ### -----------------------------------------------------------------------------\n",
    "#             # 저작권 유형\n",
    "#             try:\n",
    "#                 try:\n",
    "#                     cprt = driver.find_element(By.XPATH, cprt_attr1).get_attribute('src')\n",
    "#                 except:\n",
    "#                     cprt = driver.find_element(By.XPATH, cprt_attr2).get_attribute('src')\n",
    "#             except:\n",
    "#                 print('저작권 유형이 획득되지 않았습니다.')\n",
    "#                 cprt = ''\n",
    "#             cprt_lst.append(cprt)\n",
    "#             # --------------------------------------------------------------------------------\n",
    "#             # 로깅\n",
    "#             print('{} 페이지 {}번째 글 완료'.format((i + start_page), (j + 1)))\n",
    "#             # 사람처럼 보이기 # 반복 횟수 많아질 때 sleep 길게해 줄 필요있음(10,000개 까진 필요없는 것 같음)\n",
    "#             num_tst = random.uniform(0.01, 0.09)\n",
    "#             print(num_tst)\n",
    "#             time.sleep(num_tst)\n",
    "\n",
    "#             # time stamp 2\n",
    "#             stmp2 = datetime.now().strftime(dt_format)\n",
    "#             tm_stmp2.append(stmp2)\n",
    "\n",
    "#             time.sleep(5)\n",
    "            \n",
    "#             # 뒤로가기\n",
    "#             driver.back()\n",
    "                \n",
    "#             time.sleep(5)\n",
    "\n",
    "#             # 사람처럼 보이기 # 반복 횟수 많아질 때 sleep 길게해 줄 필요있음(10,000개 까진 필요없는 것 같음)\n",
    "#             num_tst = random.uniform(1.01, 2.09)\n",
    "#             print(num_tst)\n",
    "#             time.sleep(num_tst)\n",
    "\n",
    "#             print('cnt cp : {}'.format(cnt_cp))\n",
    "\n",
    "#         # 하단 페이지 개수에서 최대 번호 페이지일 때\n",
    "#         if cnt_cp == page_cnt:\n",
    "#             # > 버튼(다음 페이지 이동 버튼) 클릭\n",
    "#             driver.find_element(By.XPATH, nxt_btn_attr).click()\n",
    "#             # 하단 페이지 개수에서 최대 페이지 번호 마다 카운트 초기화\n",
    "#             cnt_cp = 1\n",
    "#         else:\n",
    "#             # 카운트 증가\n",
    "#             cnt_cp += 1\n",
    "            \n",
    "#         # 마지막 페이지이고 루프가 거의 끝나갈 때\n",
    "#         if i == tot_page - 1:\n",
    "#             ### 종료 시각\n",
    "#             end_dt = datetime.now().strftime(dt_format)\n",
    "#             print(end_dt)\n",
    "#             ### 종료\n",
    "#             driver.quit()\n",
    "\n",
    "#             print('데이터 수집이 완료되었습니다.')\n",
    "\n",
    "#             ## df\n",
    "#             df_out = pd.DataFrame(np.column_stack([url_lst, ttl_lst, dt_lst, cntnt_lst, fnm_lst, cprt_lst, tm_stmp1, tm_stmp2]),\n",
    "#                     columns=['URL_ADDR', 'TTL', 'DT_INFO', 'CN', 'FILE_NM', 'CP_TYPE_NM_','tm_stamp1', 'tm_stamp2'])\n",
    "# except:\n",
    "#     print('파라미터 설정을 다시 확인해 주세요.')\n",
    "#     ### 종료 시각\n",
    "#     end_dt = datetime.now().strftime(dt_format)\n",
    "#     print(end_dt)\n",
    "#     ### 종료\n",
    "#     driver.quit()\n",
    "#     ### df\n",
    "#     df_out = pd.DataFrame(np.column_stack([url_lst, ttl_lst, dt_lst, cntnt_lst, fnm_lst, cprt_lst, tm_stmp1, tm_stmp2]),\n",
    "#             columns=['URL_ADDR', 'TTL', 'DT_INFO', 'CN', 'FILE_NM', 'CP_TYPE_NM_', 'tm_stamp1','tm_stamp2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33036b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc271010",
   "metadata": {},
   "source": [
    "### Run (Click-Button method) (CSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9e3191",
   "metadata": {},
   "source": [
    "##### 버튼 클릭을 통한 페이지 이동 (URL 주소가 불규칙하게 변형될 때 사용 권장)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5797dce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### --------------------------------------------------------------------------------------------------------------\n",
    "# ### 시작 시각\n",
    "# start_dt = datetime.now().strftime(dt_format)\n",
    "# print(start_dt)\n",
    "# ### ---------------------------------------\n",
    "# driver = webdriver.Chrome(options=options)\n",
    "# #driver = webdriver.Firefox(options=options)\n",
    "# driver.maximize_window()\n",
    "# #driver.execute_script(\"document.body.style.MozTransform = 'scale(0.1)'\")\n",
    "# driver.get(url_input)\n",
    "# time.sleep(5)\n",
    "\n",
    "# url_lst, ttl_lst, dt_lst, cntnt_lst, fnm_lst, cprt_lst, tm_stmp1, tm_stmp2 = [], [], [], [], [], [], [], []\n",
    "# # 설정시의 파라미터와 실제 수집시의 파라미터가 다를 수 있으므로 예외처리\n",
    "# try:\n",
    "#     for i in range(tot_page):\n",
    "\n",
    "#         ### 페이지 클릭\n",
    "#         if cnt_cp == 0:\n",
    "#             cnt_cp = page_cnt\n",
    "     \n",
    "#         # 해당 페이지 클릭 # 현재 페이지가 굵게 표시되고 클릭이 안 되는 게시판도 있으므로 기본적으로는 주석처리함.\n",
    "#         #driver.find_element(By.CSS_SELECTOR, cpage_attr.format(cnt_cp)).click()\n",
    "        \n",
    "#         #driver.find_element(By.CSS_SELECTOR, cpage_attr).click()\n",
    "#         # 사람처럼 보이기 # 반복 횟수 많아질 때 sleep 길게해 줄 필요있음(10,000개 까진 필요없는 것 같음)\n",
    "#         num_tst = random.uniform(0.01, 0.09)\n",
    "#         print(num_tst)\n",
    "#         time.sleep(num_tst)\n",
    "\n",
    "#         ### 글 클릭하고 데이터 수집\n",
    "#         ## 예외 처리\n",
    "#         # 마지막 페이지일 때, 수집 페이지 개수가 2개 이상이고 마지막 글 개수가 0이 아닌 상황\n",
    "#         if i == tot_page - 1 and tot_page > 1 and num_a_fin != 0:\n",
    "#             cnt_a = num_a_fin\n",
    "#         # 페이지 개수 1개이고 모으는 글의 개수가 한 페이지에 있어서 글 최대 개수 이하일 때\n",
    "#         if tot_page == 1 and num_a_fin != 0 and num_a_fin <= cnt_a:\n",
    "#             cnt_a = num_a_fin\n",
    "#         # 페이지 개수 0개(start, end 같은 페이지)인데 모으는 글의 개수가 0개 이면 수집 취소\n",
    "#         if tot_page == 0 and num_a_fin == 0:\n",
    "#             print('수집할 데이터가 없습니다.')\n",
    "#             df_out = pd.DataFrame(np.column_stack([url_lst, ttl_lst, dt_lst, cntnt_lst, fnm_lst, cprt_lst, tm_stmp1, tm_stmp2]),\n",
    "#                     columns=['URL_ADDR', 'TTL', 'DT_INFO', 'CN', 'FILE_NM', 'CP_TYPE_NM_','tm_stamp1', 'tm_stamp2'])\n",
    "#         for j in range(cnt_a):\n",
    "#             # 글 클릭 (마지막 페이지 제외하고 10개씩)\n",
    "          \n",
    "#             #print(article_attr.format(j + 1))\n",
    "#             #prev_height = driver.execute_script('return document.body.scrollHeight')\n",
    "#             #print('prev height : {}'.format(prev_height))\n",
    "#             # 게시판 사이즈가 클 경우 스크롤 다운 등의 동작 추가도 필요(항시 해당되는 것은 아니므로 주석처리됨)\n",
    "#             #driver.execute_script('window.scrollTo(0,340)')\n",
    "           \n",
    "#             driver.find_element(By.CSS_SELECTOR, article_attr1.format(j + 1)).click()\n",
    "#             #driver.find_element(By.XPATH, r'//*[@id=\"boardItem\"]/a[{}]'.format(j+1)).click()\n",
    "#             #driver.find_element(By.CSS_SELECTOR, '#boardItem > a:nth-child({})'.format(j+1)).click()\n",
    "#             #'//*[@id=\"boardItem\"]/a[1]'\n",
    "#             # 글 클릭에 드는 시간에 비해 게시글 로딩 시간이 길 경우 sleep 주는 것이 필요.\n",
    "#             #time.sleep(5)\n",
    "#             #time.sleep(10)\n",
    "#             # 글 제목이 없을 경우, 사진 혹은 작성일 클릭을 권장\n",
    "#             # driver.find_element(By.CSS_SELECTOR, pic_attr.format(j + 1)).click()\n",
    "#             #driver.find_element(By.CSS_SELECTOR, dt_click_attr.format(j + 1)).click()\n",
    "#             ### 데이터 수집\n",
    "#             # URL\n",
    "#             url_str = str(driver.current_url)\n",
    "#             url_lst.append(url_str)\n",
    "#             # -------------------------------------------------------\n",
    "#             # time stamp 1\n",
    "#             stmp1 = datetime.now().strftime(dt_format)\n",
    "#             tm_stmp1.append(stmp1)\n",
    "#             # -----------------------------------------------------------------\n",
    "#             # 글 제목\n",
    "#             try:\n",
    "#                 try:\n",
    "#                     title = driver.find_element(By.CSS_SELECTOR, ttl_attr1).text\n",
    "#                 except:\n",
    "#                     title = driver.find_element(By.CSS_SELECTOR, ttl_attr2).text\n",
    "#             except:\n",
    "#                 print('제목이 획득되지 않았습니다.')\n",
    "#                 title = ''\n",
    "#             ttl_lst.append(title)\n",
    "#             # 확인용 제목 출력\n",
    "#             #print('title : {}'.format(title))\n",
    "#             # -----------------------------------------------------------------\n",
    "#             # 작성일\n",
    "#             try:\n",
    "#                 try:\n",
    "#                     date = driver.find_element(By.CSS_SELECTOR, dt_attr1).text\n",
    "#                 except:\n",
    "#                     date = driver.find_element(By.CSS_SELECTOR, dt_attr2).text\n",
    "#             except:\n",
    "#                 print('작성일이 획득되지 않았습니다.')\n",
    "#                 date = ''\n",
    "#             dt_lst.append(date)\n",
    "#             # -----------------------------------------------------------------\n",
    "#             # 내용\n",
    "#             try:\n",
    "#                 try:\n",
    "#                     cntnt = driver.find_element(By.CSS_SELECTOR, cntnt_attr1).text\n",
    "#                 except:\n",
    "#                     cntnt = driver.find_element(By.CSS_SELECTOR, cntnt_attr2).text\n",
    "#             except:\n",
    "#                 print('본문 내용이 획득되지 않았습니다.')\n",
    "#                 cntnt = ''\n",
    "#             cntnt_lst.append(cntnt)\n",
    "#             ### ----------------------------------------------------------------\n",
    "#             file_nm = driver.find_elements(By.CSS_SELECTOR, fnm_attr)\n",
    "#             if len(file_nm) == 0:\n",
    "#                 print('파일 다운로드 없음')\n",
    "#                 fnm_lst.append('')\n",
    "#             else:\n",
    "#                 file__ = []\n",
    "#                 for file_ in file_nm:\n",
    "#                     ##print(file_.text)\n",
    "#                     file__.append(file_.text)\n",
    "#                 fnm_lst.append(file__[0])\n",
    "#             # 파일 다운로드 태그가 구현이 안된 게시판의 경우 위 파일명 획득 코드를 주석처리 하고\n",
    "#             # 밑의 '' 빈 스트링 값을 추가하는 코드의 주석을 풀기 바람\n",
    "#             #fnm_lst.append('')\n",
    "#             ### -----------------------------------------------------------------------------\n",
    "#             # 저작권 유형\n",
    "#             try:\n",
    "#                 try:\n",
    "#                     cprt = driver.find_element(By.CSS_SELECTOR, cprt_attr1).get_attribute('src')\n",
    "#                 except:\n",
    "#                     cprt = driver.find_element(By.CSS_SELECTOR, cprt_attr2).get_attribute('src')\n",
    "#             except:\n",
    "#                 print('저작권 유형이 획득되지 않았습니다.')\n",
    "#                 cprt = ''\n",
    "#             cprt_lst.append(cprt)\n",
    "#             # --------------------------------------------------------------------------------\n",
    "#             # 로깅\n",
    "#             print('{} 페이지 {}번째 글 완료'.format((i + start_page), (j + 1)))\n",
    "#             # 사람처럼 보이기 # 반복 횟수 많아질 때 sleep 길게해 줄 필요있음(10,000개 까진 필요없는 것 같음)\n",
    "#             num_tst = random.uniform(0.01, 0.09)\n",
    "#             print(num_tst)\n",
    "#             time.sleep(num_tst)\n",
    "\n",
    "#             # time stamp 2\n",
    "#             stmp2 = datetime.now().strftime(dt_format)\n",
    "#             tm_stmp2.append(stmp2)\n",
    "\n",
    "#             time.sleep(5)\n",
    "            \n",
    "#             # 뒤로가기\n",
    "#             driver.back()\n",
    "                \n",
    "#             time.sleep(5)\n",
    "\n",
    "#             # 사람처럼 보이기 # 반복 횟수 많아질 때 sleep 길게해 줄 필요있음(10,000개 까진 필요없는 것 같음)\n",
    "#             num_tst = random.uniform(1.01, 2.09)\n",
    "#             print(num_tst)\n",
    "#             time.sleep(num_tst)\n",
    "\n",
    "#             print('cnt cp : {}'.format(cnt_cp))\n",
    "\n",
    "#         # 하단 페이지 개수에서 최대 번호 페이지일 때\n",
    "#         if cnt_cp == page_cnt:\n",
    "#             # > 버튼(다음 페이지 이동 버튼) 클릭\n",
    "#             driver.find_element(By.CSS_SELECTOR, nxt_btn_attr).click()\n",
    "#             # 하단 페이지 개수에서 최대 페이지 번호 마다 카운트 초기화\n",
    "#             cnt_cp = 1\n",
    "#         else:\n",
    "#             # 카운트 증가\n",
    "#             cnt_cp += 1\n",
    "            \n",
    "#         # 마지막 페이지이고 루프가 거의 끝나갈 때\n",
    "#         if i == tot_page - 1:\n",
    "#             ### 종료 시각\n",
    "#             end_dt = datetime.now().strftime(dt_format)\n",
    "#             print(end_dt)\n",
    "#             ### 종료\n",
    "#             driver.quit()\n",
    "\n",
    "#             print('데이터 수집이 완료되었습니다.')\n",
    "\n",
    "#             ## df\n",
    "#             df_out = pd.DataFrame(np.column_stack([url_lst, ttl_lst, dt_lst, cntnt_lst, fnm_lst, cprt_lst, tm_stmp1, tm_stmp2]),\n",
    "#                     columns=['URL_ADDR', 'TTL', 'DT_INFO', 'CN', 'FILE_NM', 'CP_TYPE_NM_','tm_stamp1', 'tm_stamp2'])\n",
    "# except:\n",
    "#     print('파라미터 설정을 다시 확인해 주세요.')\n",
    "#     ### 종료 시각\n",
    "#     end_dt = datetime.now().strftime(dt_format)\n",
    "#     print(end_dt)\n",
    "#     ### 종료\n",
    "#     driver.quit()\n",
    "#     ### df\n",
    "#     df_out = pd.DataFrame(np.column_stack([url_lst, ttl_lst, dt_lst, cntnt_lst, fnm_lst, cprt_lst, tm_stmp1, tm_stmp2]),\n",
    "#             columns=['URL_ADDR', 'TTL', 'DT_INFO', 'CN', 'FILE_NM', 'CP_TYPE_NM_', 'tm_stamp1','tm_stamp2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f848561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### OLD\n",
    "# len_lst_old = [len(url_lst), len(ttl_lst), len(dt_lst), len(cntnt_lst), len(fnm_lst), len(cprt_lst), len(tm_stmp1), len(tm_stmp2)]\n",
    "# print(len_lst_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05da222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### OLD\n",
    "# if len(url_lst) == len(ttl_lst) == len(dt_lst) == len(cntnt_lst) == len(fnm_lst) == len(cprt_lst) == len(tm_stmp1) == len(tm_stmp2):\n",
    "#     df_out = pd.DataFrame(np.column_stack([url_lst, ttl_lst, dt_lst, cntnt_lst, fnm_lst, cprt_lst, tm_stmp1, tm_stmp2]),\n",
    "#                       columns=['URL_ADDR', 'TTL', 'DT_INFO', 'CN', 'FILE_NM','CP_TYPE_NM_', 'tm_stamp1','tm_stamp2'])\n",
    "# else:\n",
    "#     num_limit = min(len_lst_old)\n",
    "#     df_out = pd.DataFrame(np.column_stack([url_lst[:num_limit], ttl_lst[:num_limit], dt_lst[:num_limit], cntnt_lst[:num_limit], fnm_lst[:num_limit], cprt_lst[:num_limit], tm_stmp1[:num_limit], tm_stmp2[:num_limit]]),\n",
    "#                       columns=['URL_ADDR', 'TTL', 'DT_INFO', 'CN', 'FILE_NM','CP_TYPE_NM_', 'tm_stamp1','tm_stamp2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c28d799",
   "metadata": {},
   "source": [
    "### Preprocessing (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04637f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### OLD\n",
    "# preprocess(df_out,bbs_sn_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7cdfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### OLD\n",
    "# folder_nm_old = 'CSV'\n",
    "# dir_main = os.getcwd()\n",
    "# os.makedirs(folder_nm_old, exist_ok=True)\n",
    "# save_dir_old = os.path.join(dir_main,folder_nm_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033d08fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### OLD\n",
    "# print(save_dir_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27405f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### OLD\n",
    "# started_tm = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "# file_nm_old1 = 'crawler_{}_part1_{}.csv'.format(bbs_sn_num,started_tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6d961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### OLD\n",
    "# df_out.to_csv(os.path.join(save_dir_old,file_nm_old1),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17809b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98dd2bad",
   "metadata": {},
   "source": [
    "### Preprocessing (new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60e63e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEW\n",
    "len_lst = [len(url_pg_lst), len(url_lst), len(ttl_lst), len(dt_lst), len(cntnt_lst), len(cprt_lst)]\n",
    "print(len_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa090d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbbbb\n"
     ]
    }
   ],
   "source": [
    "### NEW\n",
    "if len(url_pg_lst) == len(url_lst) == len(ttl_lst) == len(dt_lst) == len(cntnt_lst) == len(cprt_lst):\n",
    "    df_out = pd.DataFrame(np.column_stack([url_pg_lst, url_lst, ttl_lst, dt_lst, cntnt_lst, cprt_lst]),\n",
    "                      columns=['ATC_LIST_URL', 'ATC_URL', 'ATC_TITLE', 'ENROLL_DATE', 'ATC_CONTENTS', 'RGT_TYPE_CODE_'])\n",
    "else:\n",
    "    num_limit = min(len_lst)\n",
    "    df_out = pd.DataFrame(np.column_stack([url_pg_lst[:num_limit], url_lst[:num_limit], ttl_lst[:num_limit], dt_lst[:num_limit], cntnt_lst[:num_limit], cprt_lst[:num_limit]]),\n",
    "                      columns=['ATC_LIST_URL', 'ATC_URL', 'ATC_TITLE', 'ENROLL_DATE', 'ATC_CONTENTS', 'RGT_TYPE_CODE_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "519eff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_xlsx(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3301c8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdi_reformer(df_out)\n",
    "pdi_reformer2(df_out)\n",
    "pdi_reformer3(df_out)\n",
    "pdi_reformer4(df_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584e6082",
   "metadata": {},
   "source": [
    "### Saving the data (new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceb8a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEW\n",
    "folder_nm = 'EXCEL'\n",
    "dir_main = os.getcwd()\n",
    "os.makedirs(folder_nm, exist_ok=True)\n",
    "save_dir = os.path.join(dir_main, folder_nm)\n",
    "started_tm = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "file_nm = 'work_{}.xlsx'.format(started_tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98f0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEW\n",
    "### 엑셀파일 저장\n",
    "df_out.to_excel(os.path.join(save_dir,file_nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b44190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e52734c8",
   "metadata": {},
   "source": [
    "### 'CN_LINK_ADDR' (CLA) (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ee9a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 페이지 별로 'CN_LINK_ADDR'들을 한 꺼번에 구함 # 예 1페이지, 10개의 PCLA\n",
    "# # 추후 필요시 커스텀 바람\n",
    "# pcla_lst2_ = []\n",
    "# for i in range(tot_page):\n",
    "#     url_input_ = str(url_str_.format(start_page + i))\n",
    "#     wpage = requests.get(url_input_, verify=False)\n",
    "#     html_enc = wpage.text.encode('utf-8')\n",
    "#     soup_ = BeautifulSoup(html_enc, 'html.parser')\n",
    "#     # select : 한꺼번에 선택\n",
    "#     ul = soup_.select(pcla_css)\n",
    "#     # 선택된 <a href ...> 태그가 1개 이상일 때\n",
    "#     if len(ul) != 0:\n",
    "#         # 일반적인 경우\n",
    "#         cnt_a_ = len(ul)\n",
    "#         # 예외처리\n",
    "#         # 마지막 페이지, 수집 페이지 개수 2개 이상, 마지막 글 개수 0이 아님\n",
    "#         if i == tot_page - 1 and tot_page > 1 and num_a_fin != 0:\n",
    "#             cnt_a_ = num_a_fin\n",
    "#         # 페이지 개수 1개이고 모으는 글의 개수가 한 페이지에 있어서 글 최대 개수 이하일 때\n",
    "#         if tot_page == 1 and num_a_fin != 0 and num_a_fin <= len(ul):\n",
    "#             cnt_a_ = num_a_fin\n",
    "#         # 페이지 개수 0개(start, end 같은 페이지)인데 모으는 글의 개수가 0개 이면 수집 취소\n",
    "#         if tot_page == 0 and num_a_fin == 0:\n",
    "#             print('수집할 데이터가 없습니다.')\n",
    "#             pcla_lst2_.append('')\n",
    "#             break\n",
    "#         for j in range(cnt_a_):\n",
    "#             #print(str(ul[j]))\n",
    "#             #print('*'*20)\n",
    "#             pcla_lst2_.append(str(ul[j]))\n",
    "#     ### -------------------------------------------------------------------------------------------------\n",
    "#     print('{} 번째 페이지 수집 완료'.format(i + start_page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5960791c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### OLD\n",
    "# df_out2 = pd.DataFrame({'CN_LINK_ADDR': pcla_lst2_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9512251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### OLD\n",
    "# started_tm = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "# file_nm_old2 = 'crawler_{}_part2_{}.csv'.format(bbs_sn_num,started_tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca37c1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### OLD\n",
    "# df_out2.to_csv(os.path.join(save_dir_old,file_nm_old2),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b289fa20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b754f697",
   "metadata": {},
   "source": [
    "### Integrity Test (Old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770716ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762ccf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 정합성 체크 구현 필요..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c68256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c567311f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_out), len(df_out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c79630ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_out) == len(df_out2):\n",
    "    # 서로 합치기\n",
    "    df_out3 = pd.concat([df_out, df_out2], axis=1)\n",
    "    unnamed_cols = [col for col in df_out3.columns if 'Unnamed' in col]\n",
    "    df_out3.drop(unnamed_cols, axis='columns', inplace=True)\n",
    "else:\n",
    "    # 정합성 안 맞을 경우 각각의 데이터를 파일로 저장\n",
    "    print('정합성이 안 맞습니다. 코드 관리자에게 문의주세요.')\n",
    "    df_out.to_csv(save_dir + 'df_crawler_{}_part1_{}.csv'.format(bbs_sn_num,started_tm),index=False)\n",
    "    df_out2.to_csv(save_dir + 'df_crawler_{}_part2_{}.csv'.format(bbs_sn_num,started_tm),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b68822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a981cc7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cf5e45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d5a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7721d355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c6e4ade",
   "metadata": {},
   "source": [
    "### Preprocessing 2 (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6cbc8177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_out3_ = puvi_prprc(df_out3)\n",
    "# df_out4 = col_organizer(df_out3_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d27240",
   "metadata": {},
   "source": [
    "### Saving the data (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1016b67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'CLCT_INFO'의 데이터 수집이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# # CLCT_INFO용 데이터 저장\n",
    "# df_out4.to_csv(save_dir + \"df_clct_info_{}_{}.csv\".format(bbs_sn_num,started_tm),index=False)\n",
    "# print(\"'CLCT_INFO'의 데이터 수집이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1113f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_out5 = df_out4.copy(deep=True)\n",
    "# df_out5_ = ci_dtl_maker(df_out5)\n",
    "# df_out6 = col_organizer(df_out5_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a74fd4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'CLCT_INFO_DTL'의 데이터 수집이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# # CLCT_INFO_DTL용 데이터 저장\n",
    "# df_out6.to_csv(save_dir + \"df_clct_info_dtl_{}_{}.csv\".format(bbs_sn_num,started_tm),index=False)\n",
    "# print(\"'CLCT_INFO_DTL'의 데이터 수집이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3a607ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수고하셨습니다.\n",
      "다른 게시판 작업이 남았을 경우, 다음 게시판으로 넘어가주세요.\n"
     ]
    }
   ],
   "source": [
    "# print('수고하셨습니다.')\n",
    "# print('다른 게시판 작업이 남았을 경우, 다음 게시판으로 넘어가주세요.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275287e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8715bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
